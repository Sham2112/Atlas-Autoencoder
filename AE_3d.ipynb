{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AE_3d.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP2qceN3vXbDPrTdf5aWfjm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "815oIzH7HaRs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from nn_utils import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQLjYm_MIQD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infile = open('all_jets_train_4D_100_percent.pkl', 'rb')\n",
        "traindata = pickle.load(infile)\n",
        "infile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Qnbc8oIV0J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infile = open('all_jets_test_4D_100_percent.pkl', 'rb')\n",
        "testdata = pickle.load(infile)\n",
        "infile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47whJKIvIY-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Normalize\n",
        "train_mean = traindata.mean()\n",
        "train_std = traindata.std()\n",
        "\n",
        "traindata = (traindata - train_mean) / train_std\n",
        "testdata = (testdata - train_mean) / train_std"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cz6IfuaiIuXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x = traindata\n",
        "test_x = testdata\n",
        "train_y = train_x\n",
        "test_y = test_x\n",
        "\n",
        "trainset = TensorDataset(torch.tensor(train_x.values, dtype=torch.float), torch.tensor(train_y.values, dtype=torch.float))\n",
        "validset = TensorDataset(torch.tensor(test_x.values, dtype=torch.float), torch.tensor(test_y.values, dtype=torch.float))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R3Ept5eSIzxP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=32, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtyKlAziiA8Z",
        "colab_type": "code",
        "outputId": "f15fd062-f43d-459a-c779-a686999f9ea5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "print(\"Using: \", device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using:  cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijmqldVtkQzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Let's experiment with different Activation functions"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_EJ4zk6iEkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_epochs = 40\n",
        "model_lr = AE_3d_LeakyReLU().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_lr.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wu0AvHdljhgA",
        "colab_type": "code",
        "outputId": "de7ae3a5-8e41-45c7-ebf8-5ca4255f9652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "source": [
        "model_lr, train_losses, valid_losses = fit(n_epochs, criterion, optimizer, model_lr, trainloader, validloader, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 0.04737720942419528, Validation loss: 0.03385604480526557\n",
            "Validation loss decreased (inf --> 0.03385604480526557).  Saving model ...\n",
            "Epoch: 2, Training loss: 0.032145200373069664, Validation loss: 0.03395677939509159\n",
            "Epoch: 3, Training loss: 0.032004250765460394, Validation loss: 0.03419821865609431\n",
            "Epoch: 4, Training loss: 0.032008536450397466, Validation loss: 0.033251363955101414\n",
            "Validation loss decreased (0.03385604480526557 --> 0.033251363955101414).  Saving model ...\n",
            "Epoch: 5, Training loss: 0.03195710942715846, Validation loss: 0.03373888754062099\n",
            "Epoch: 6, Training loss: 0.03188963315302253, Validation loss: 0.03348783044212709\n",
            "Epoch: 7, Training loss: 0.0319440913886156, Validation loss: 0.03344541272250786\n",
            "Epoch: 8, Training loss: 0.03184315889004115, Validation loss: 0.033346569161857874\n",
            "Epoch: 9, Training loss: 0.0318607146994722, Validation loss: 0.03331899858645677\n",
            "Epoch: 10, Training loss: 0.03185375364647804, Validation loss: 0.03339114297621988\n",
            "Epoch: 11, Training loss: 0.03185893759419571, Validation loss: 0.03339903406107274\n",
            "Epoch: 12, Training loss: 0.03183290709792774, Validation loss: 0.03329479194979356\n",
            "Epoch: 13, Training loss: 0.031836959155226836, Validation loss: 0.0336365890939607\n",
            "Epoch: 14, Training loss: 0.03182894498979834, Validation loss: 0.033416882674934374\n",
            "Epoch: 15, Training loss: 0.031803844042008284, Validation loss: 0.03331648444626864\n",
            "Epoch: 16, Training loss: 0.0318350901088342, Validation loss: 0.033259816796229025\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-ec541ba4289b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/nn_utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(n_epochs, criterion, optimizer, model, trainloader, validloader, device)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m             \u001b[0mrunning_train_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWEEn4DUI1rl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#We see that Leaky ReLU does not improve performance"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q-RaIfrkm2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_lr.state_dict(), 'model_lr.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UhQJ91Ysmh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_th = AE_3d_tanh().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_th.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxamSvaQtDWo",
        "colab_type": "code",
        "outputId": "6d2e539f-fea0-48fa-88ba-1344d6762fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_th, train_losses, valid_losses = fit(n_epochs, criterion, optimizer, model_th, trainloader, validloader, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 0.05849870507425187, Validation loss: 0.03541364198421646\n",
            "Validation loss decreased (inf --> 0.03541364198421646).  Saving model ...\n",
            "Epoch: 2, Training loss: 0.03124683652331431, Validation loss: 0.03298726030790569\n",
            "Validation loss decreased (0.03541364198421646 --> 0.03298726030790569).  Saving model ...\n",
            "Epoch: 3, Training loss: 0.029929853972241082, Validation loss: 0.03166826735506392\n",
            "Validation loss decreased (0.03298726030790569 --> 0.03166826735506392).  Saving model ...\n",
            "Epoch: 4, Training loss: 0.029328589698203275, Validation loss: 0.031121559729863562\n",
            "Validation loss decreased (0.03166826735506392 --> 0.031121559729863562).  Saving model ...\n",
            "Epoch: 5, Training loss: 0.02860502177857675, Validation loss: 0.030253067324007274\n",
            "Validation loss decreased (0.031121559729863562 --> 0.030253067324007274).  Saving model ...\n",
            "Epoch: 6, Training loss: 0.026796107215401155, Validation loss: 0.02629162068505403\n",
            "Validation loss decreased (0.030253067324007274 --> 0.02629162068505403).  Saving model ...\n",
            "Epoch: 7, Training loss: 0.02379963970394607, Validation loss: 0.02374988780474158\n",
            "Validation loss decreased (0.02629162068505403 --> 0.02374988780474158).  Saving model ...\n",
            "Epoch: 8, Training loss: 0.022187488882388744, Validation loss: 0.02257900037248651\n",
            "Validation loss decreased (0.02374988780474158 --> 0.02257900037248651).  Saving model ...\n",
            "Epoch: 9, Training loss: 0.021471014748189896, Validation loss: 0.022240746172797147\n",
            "Validation loss decreased (0.02257900037248651 --> 0.022240746172797147).  Saving model ...\n",
            "Epoch: 10, Training loss: 0.020823143862634532, Validation loss: 0.021440502558648374\n",
            "Validation loss decreased (0.022240746172797147 --> 0.021440502558648374).  Saving model ...\n",
            "Epoch: 11, Training loss: 0.02015685235882102, Validation loss: 0.021558295184686712\n",
            "Epoch: 12, Training loss: 0.019618256009835803, Validation loss: 0.022289747819815946\n",
            "Epoch: 13, Training loss: 0.018942590499075283, Validation loss: 0.019325917549521898\n",
            "Validation loss decreased (0.021440502558648374 --> 0.019325917549521898).  Saving model ...\n",
            "Epoch: 14, Training loss: 0.018520861942821907, Validation loss: 0.020539317925533096\n",
            "Epoch: 15, Training loss: 0.017904445147643926, Validation loss: 0.019500831647821886\n",
            "Epoch: 16, Training loss: 0.017413519970086708, Validation loss: 0.017919278479590416\n",
            "Validation loss decreased (0.019325917549521898 --> 0.017919278479590416).  Saving model ...\n",
            "Epoch: 17, Training loss: 0.01699573950583204, Validation loss: 0.017019666963389028\n",
            "Validation loss decreased (0.017919278479590416 --> 0.017019666963389028).  Saving model ...\n",
            "Epoch: 18, Training loss: 0.016549271552193896, Validation loss: 0.017707613362873173\n",
            "Epoch: 19, Training loss: 0.016602647742155235, Validation loss: 0.016511653756959368\n",
            "Validation loss decreased (0.017019666963389028 --> 0.016511653756959368).  Saving model ...\n",
            "Epoch: 20, Training loss: 0.01614559715729072, Validation loss: 0.01608169232191437\n",
            "Validation loss decreased (0.016511653756959368 --> 0.01608169232191437).  Saving model ...\n",
            "Epoch: 21, Training loss: 0.015717072040568953, Validation loss: 0.01614657086288254\n",
            "Epoch: 22, Training loss: 0.015513583376136586, Validation loss: 0.015102884211115011\n",
            "Validation loss decreased (0.01608169232191437 --> 0.015102884211115011).  Saving model ...\n",
            "Epoch: 23, Training loss: 0.014931458172601081, Validation loss: 0.015220670172975567\n",
            "Epoch: 24, Training loss: 0.015289699319467795, Validation loss: 0.015144412078920248\n",
            "Epoch: 25, Training loss: 0.014620462178182535, Validation loss: 0.015639495504945432\n",
            "Epoch: 26, Training loss: 0.014442008884537885, Validation loss: 0.014459097222744719\n",
            "Validation loss decreased (0.015102884211115011 --> 0.014459097222744719).  Saving model ...\n",
            "Epoch: 27, Training loss: 0.014324274422041379, Validation loss: 0.014882719450314833\n",
            "Epoch: 28, Training loss: 0.01410683408501101, Validation loss: 0.01413326788130504\n",
            "Validation loss decreased (0.014459097222744719 --> 0.01413326788130504).  Saving model ...\n",
            "Epoch: 29, Training loss: 0.013991647513062066, Validation loss: 0.014612920851754642\n",
            "Epoch: 30, Training loss: 0.013882147011195315, Validation loss: 0.01469385678409993\n",
            "Epoch: 31, Training loss: 0.013681203055105683, Validation loss: 0.014186067347898568\n",
            "Epoch: 32, Training loss: 0.013522172385294141, Validation loss: 0.013985809626311354\n",
            "Validation loss decreased (0.01413326788130504 --> 0.013985809626311354).  Saving model ...\n",
            "Epoch: 33, Training loss: 0.013540036736843062, Validation loss: 0.014123040320963367\n",
            "Epoch: 34, Training loss: 0.01320431156456577, Validation loss: 0.01383778077440477\n",
            "Validation loss decreased (0.013985809626311354 --> 0.01383778077440477).  Saving model ...\n",
            "Epoch: 35, Training loss: 0.012935380741419951, Validation loss: 0.014252328178158042\n",
            "Epoch: 36, Training loss: 0.013131741111394807, Validation loss: 0.013532452547157639\n",
            "Validation loss decreased (0.01383778077440477 --> 0.013532452547157639).  Saving model ...\n",
            "Epoch: 37, Training loss: 0.012812355338494785, Validation loss: 0.01287584014058974\n",
            "Validation loss decreased (0.013532452547157639 --> 0.01287584014058974).  Saving model ...\n",
            "Epoch: 38, Training loss: 0.0127529940010923, Validation loss: 0.012919127211870851\n",
            "Epoch: 39, Training loss: 0.012731806907651421, Validation loss: 0.01297662460985242\n",
            "Epoch: 40, Training loss: 0.012600652711587501, Validation loss: 0.012987345799130284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tu4fmyDmL_kE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Tanh activation function also performed really well"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0YgN2_wwsWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_th.state_dict(), 'model_th.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IPPyL831wha",
        "colab_type": "code",
        "outputId": "3639a193-efe5-434b-8c74-c9a23c5328d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "plt.plot(train_losses)\n",
        "plt.plot(valid_losses)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD5CAYAAAAp8/5SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEZGQU9CLiIScgl5EJOT+Pyj2je1k3/viAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F__gRsmoKbL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now lets try different architectures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGxI7ehNMs1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_small = AE_3d_small().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_small.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKvGVwUtM5mu",
        "colab_type": "code",
        "outputId": "d4653114-d453-4de1-cc8b-4703310081bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model_small, train_losses, valid_losses = fit(n_epochs, criterion, optimizer, model_small, trainloader, validloader, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 0.17710668407963656, Validation loss: 0.030805615813991383\n",
            "Validation loss decreased (inf --> 0.030805615813991383).  Saving model ...\n",
            "Epoch: 2, Training loss: 0.027755664099307978, Validation loss: 0.02840226312254255\n",
            "Validation loss decreased (0.030805615813991383 --> 0.02840226312254255).  Saving model ...\n",
            "Epoch: 3, Training loss: 0.026086107265687577, Validation loss: 0.027074122823134397\n",
            "Validation loss decreased (0.02840226312254255 --> 0.027074122823134397).  Saving model ...\n",
            "Epoch: 4, Training loss: 0.025074016619550995, Validation loss: 0.02635261500430095\n",
            "Validation loss decreased (0.027074122823134397 --> 0.02635261500430095).  Saving model ...\n",
            "Epoch: 5, Training loss: 0.024134598104290545, Validation loss: 0.024824739062734528\n",
            "Validation loss decreased (0.02635261500430095 --> 0.024824739062734528).  Saving model ...\n",
            "Epoch: 6, Training loss: 0.023247901240508188, Validation loss: 0.023684522139576628\n",
            "Validation loss decreased (0.024824739062734528 --> 0.023684522139576628).  Saving model ...\n",
            "Epoch: 7, Training loss: 0.02240726606748004, Validation loss: 0.022659154585003213\n",
            "Validation loss decreased (0.023684522139576628 --> 0.022659154585003213).  Saving model ...\n",
            "Epoch: 8, Training loss: 0.021727843389355402, Validation loss: 0.021829228884315658\n",
            "Validation loss decreased (0.022659154585003213 --> 0.021829228884315658).  Saving model ...\n",
            "Epoch: 9, Training loss: 0.021251360858777515, Validation loss: 0.021243536288879847\n",
            "Validation loss decreased (0.021829228884315658 --> 0.021243536288879847).  Saving model ...\n",
            "Epoch: 10, Training loss: 0.020851809889259127, Validation loss: 0.021138884557770177\n",
            "Validation loss decreased (0.021243536288879847 --> 0.021138884557770177).  Saving model ...\n",
            "Epoch: 11, Training loss: 0.02053800798028587, Validation loss: 0.020722754372899724\n",
            "Validation loss decreased (0.021138884557770177 --> 0.020722754372899724).  Saving model ...\n",
            "Epoch: 12, Training loss: 0.020225882722494263, Validation loss: 0.02026467621542228\n",
            "Validation loss decreased (0.020722754372899724 --> 0.02026467621542228).  Saving model ...\n",
            "Epoch: 13, Training loss: 0.019922785421866183, Validation loss: 0.020200294445938\n",
            "Validation loss decreased (0.02026467621542228 --> 0.020200294445938).  Saving model ...\n",
            "Epoch: 14, Training loss: 0.019603031836539393, Validation loss: 0.019720128656272273\n",
            "Validation loss decreased (0.020200294445938 --> 0.019720128656272273).  Saving model ...\n",
            "Epoch: 15, Training loss: 0.0193671232368144, Validation loss: 0.019313363681917103\n",
            "Validation loss decreased (0.019720128656272273 --> 0.019313363681917103).  Saving model ...\n",
            "Epoch: 16, Training loss: 0.019092049543790728, Validation loss: 0.018952417270774853\n",
            "Validation loss decreased (0.019313363681917103 --> 0.018952417270774853).  Saving model ...\n",
            "Epoch: 17, Training loss: 0.018781413732247287, Validation loss: 0.01881044728759233\n",
            "Validation loss decreased (0.018952417270774853 --> 0.01881044728759233).  Saving model ...\n",
            "Epoch: 18, Training loss: 0.018503442464826617, Validation loss: 0.01835327663829708\n",
            "Validation loss decreased (0.01881044728759233 --> 0.01835327663829708).  Saving model ...\n",
            "Epoch: 19, Training loss: 0.01824424339360523, Validation loss: 0.018083814483346925\n",
            "Validation loss decreased (0.01835327663829708 --> 0.018083814483346925).  Saving model ...\n",
            "Epoch: 20, Training loss: 0.017994572647225378, Validation loss: 0.01780585955694697\n",
            "Validation loss decreased (0.018083814483346925 --> 0.01780585955694697).  Saving model ...\n",
            "Epoch: 21, Training loss: 0.017761725991133775, Validation loss: 0.018120182728452408\n",
            "Epoch: 22, Training loss: 0.017547532558743296, Validation loss: 0.01765266104584807\n",
            "Validation loss decreased (0.01780585955694697 --> 0.01765266104584807).  Saving model ...\n",
            "Epoch: 23, Training loss: 0.017301097902323134, Validation loss: 0.01709679158183893\n",
            "Validation loss decreased (0.01765266104584807 --> 0.01709679158183893).  Saving model ...\n",
            "Epoch: 24, Training loss: 0.0171251771371598, Validation loss: 0.016866082131640998\n",
            "Validation loss decreased (0.01709679158183893 --> 0.016866082131640998).  Saving model ...\n",
            "Epoch: 25, Training loss: 0.016926043923769247, Validation loss: 0.01682602695375361\n",
            "Validation loss decreased (0.016866082131640998 --> 0.01682602695375361).  Saving model ...\n",
            "Epoch: 26, Training loss: 0.016739995647024556, Validation loss: 0.016628007812093032\n",
            "Validation loss decreased (0.01682602695375361 --> 0.016628007812093032).  Saving model ...\n",
            "Epoch: 27, Training loss: 0.01657848400071143, Validation loss: 0.016389266992183894\n",
            "Validation loss decreased (0.016628007812093032 --> 0.016389266992183894).  Saving model ...\n",
            "Epoch: 28, Training loss: 0.016394415874706938, Validation loss: 0.016496142042423566\n",
            "Epoch: 29, Training loss: 0.01623028844650631, Validation loss: 0.016299888648538163\n",
            "Validation loss decreased (0.016389266992183894 --> 0.016299888648538163).  Saving model ...\n",
            "Epoch: 30, Training loss: 0.016082774237444235, Validation loss: 0.016274281943406594\n",
            "Validation loss decreased (0.016299888648538163 --> 0.016274281943406594).  Saving model ...\n",
            "Epoch: 31, Training loss: 0.01594812840034779, Validation loss: 0.01580079334859419\n",
            "Validation loss decreased (0.016274281943406594 --> 0.01580079334859419).  Saving model ...\n",
            "Epoch: 32, Training loss: 0.01579987386942046, Validation loss: 0.016010464173347373\n",
            "Epoch: 33, Training loss: 0.015662246470055187, Validation loss: 0.0156529155512952\n",
            "Validation loss decreased (0.01580079334859419 --> 0.0156529155512952).  Saving model ...\n",
            "Epoch: 34, Training loss: 0.015521049592762258, Validation loss: 0.015490111765836406\n",
            "Validation loss decreased (0.0156529155512952 --> 0.015490111765836406).  Saving model ...\n",
            "Epoch: 35, Training loss: 0.01536286218047465, Validation loss: 0.015349438418772763\n",
            "Validation loss decreased (0.015490111765836406 --> 0.015349438418772763).  Saving model ...\n",
            "Epoch: 36, Training loss: 0.015291125591712112, Validation loss: 0.015252704014847145\n",
            "Validation loss decreased (0.015349438418772763 --> 0.015252704014847145).  Saving model ...\n",
            "Epoch: 37, Training loss: 0.015162790466900158, Validation loss: 0.0152693538312764\n",
            "Epoch: 38, Training loss: 0.015061871927485706, Validation loss: 0.015006308112846522\n",
            "Validation loss decreased (0.015252704014847145 --> 0.015006308112846522).  Saving model ...\n",
            "Epoch: 39, Training loss: 0.014958734172853493, Validation loss: 0.01509721151252599\n",
            "Epoch: 40, Training loss: 0.014861871169585046, Validation loss: 0.015171914373804737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB9qhYNxPhp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#This smalled model also achieved pretty good results but worse than the baseline model, so maybe a model of greater complexity would perform better? "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7UgFNebhND35",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_small.state_dict(), 'model_small.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrh2jFa6Pg8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_big = AE_3d_big().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_big.parameters(), lr=1e-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zo-wGgPFP03S",
        "colab_type": "code",
        "outputId": "e37d9e35-dcd1-453d-e06f-3d30be3e62c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "model_big, train_losses, valid_losses = fit(n_epochs, criterion, optimizer, model_big, trainloader, validloader, device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 0.06686789453455845, Validation loss: 0.03182895383232825\n",
            "Validation loss decreased (inf --> 0.03182895383232825).  Saving model ...\n",
            "Epoch: 2, Training loss: 0.026116360132179998, Validation loss: 0.023640787257179958\n",
            "Validation loss decreased (0.03182895383232825 --> 0.023640787257179958).  Saving model ...\n",
            "Epoch: 3, Training loss: 0.022103866256915277, Validation loss: 0.024467275853565035\n",
            "Epoch: 4, Training loss: 0.01905563269704783, Validation loss: 0.01674901589312222\n",
            "Validation loss decreased (0.023640787257179958 --> 0.01674901589312222).  Saving model ...\n",
            "Epoch: 5, Training loss: 0.016778915509598626, Validation loss: 0.016857386842951842\n",
            "Epoch: 6, Training loss: 0.015516083798461616, Validation loss: 0.017356750740215726\n",
            "Epoch: 7, Training loss: 0.01433839823358437, Validation loss: 0.014413835553801884\n",
            "Validation loss decreased (0.01674901589312222 --> 0.014413835553801884).  Saving model ...\n",
            "Epoch: 8, Training loss: 0.01425435375523528, Validation loss: 0.014099290678373514\n",
            "Validation loss decreased (0.014413835553801884 --> 0.014099290678373514).  Saving model ...\n",
            "Epoch: 9, Training loss: 0.013227589133921393, Validation loss: 0.013533939716397643\n",
            "Validation loss decreased (0.014099290678373514 --> 0.013533939716397643).  Saving model ...\n",
            "Epoch: 10, Training loss: 0.012859938184503608, Validation loss: 0.011776962652120491\n",
            "Validation loss decreased (0.013533939716397643 --> 0.011776962652120491).  Saving model ...\n",
            "Epoch: 11, Training loss: 0.01238716750934962, Validation loss: 0.011823604869852332\n",
            "Epoch: 12, Training loss: 0.011670430622604139, Validation loss: 0.011595260090161609\n",
            "Validation loss decreased (0.011776962652120491 --> 0.011595260090161609).  Saving model ...\n",
            "Epoch: 13, Training loss: 0.011335875266913962, Validation loss: 0.01146259517046608\n",
            "Validation loss decreased (0.011595260090161609 --> 0.01146259517046608).  Saving model ...\n",
            "Epoch: 14, Training loss: 0.010462704813907495, Validation loss: 0.010448110331296367\n",
            "Validation loss decreased (0.01146259517046608 --> 0.010448110331296367).  Saving model ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRVirEIXUQrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Lets add some regularization techniques"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_1CbdR6P76F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_drop = AE_3d_dropout().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_drop.parameters(), lr=1e-3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIIZoM7rU-2X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 903
        },
        "outputId": "96ed011c-e5dd-4009-b67a-e844fd535151"
      },
      "source": [
        "model_drop, train_losses, valid_losses = fit(n_epochs, criterion, optimizer, model_drop, trainloader, validloader, device)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 0.06082287816193251, Validation loss: 0.06159507606425738\n",
            "Validation loss decreased (inf --> 0.06159507606425738).  Saving model ...\n",
            "Epoch: 2, Training loss: 0.059425745752192796, Validation loss: 0.05868726400594553\n",
            "Validation loss decreased (0.06159507606425738 --> 0.05868726400594553).  Saving model ...\n",
            "Epoch: 3, Training loss: 0.05927781391735325, Validation loss: 0.058136902046251354\n",
            "Validation loss decreased (0.05868726400594553 --> 0.058136902046251354).  Saving model ...\n",
            "Epoch: 4, Training loss: 0.05823421736984046, Validation loss: 0.06268306017706268\n",
            "Epoch: 5, Training loss: 0.058485257863128394, Validation loss: 0.058547373481725666\n",
            "Epoch: 6, Training loss: 0.05761674193225046, Validation loss: 0.06354420577352803\n",
            "Epoch: 7, Training loss: 0.0578907986379985, Validation loss: 0.05712435303098209\n",
            "Validation loss decreased (0.058136902046251354 --> 0.05712435303098209).  Saving model ...\n",
            "Epoch: 8, Training loss: 0.05738225295067124, Validation loss: 0.05814117955542607\n",
            "Epoch: 9, Training loss: 0.056672777527965644, Validation loss: 0.06020715325704224\n",
            "Epoch: 10, Training loss: 0.05688394595984568, Validation loss: 0.05602967054785594\n",
            "Validation loss decreased (0.05712435303098209 --> 0.05602967054785594).  Saving model ...\n",
            "Epoch: 11, Training loss: 0.05648696183162498, Validation loss: 0.059949578257017605\n",
            "Epoch: 12, Training loss: 0.057547849262880646, Validation loss: 0.05782054283696672\n",
            "Epoch: 13, Training loss: 0.055931440227770024, Validation loss: 0.05676350722758598\n",
            "Epoch: 14, Training loss: 0.05696884255363693, Validation loss: 0.06609513501059136\n",
            "Epoch: 15, Training loss: 0.056906752355511896, Validation loss: 0.05698908042179706\n",
            "Epoch: 16, Training loss: 0.05589217200777192, Validation loss: 0.057355848569380335\n",
            "Epoch: 17, Training loss: 0.055093311940058086, Validation loss: 0.05653304458985817\n",
            "Epoch: 18, Training loss: 0.055230248823941064, Validation loss: 0.05868973132879292\n",
            "Epoch: 19, Training loss: 0.05531411471818779, Validation loss: 0.05665437050283092\n",
            "Epoch: 20, Training loss: 0.05404863975042265, Validation loss: 0.06340741127030391\n",
            "Epoch: 21, Training loss: 0.05472231969668071, Validation loss: 0.05526930012141335\n",
            "Validation loss decreased (0.05602967054785594 --> 0.05526930012141335).  Saving model ...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-ead35331fba0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_drop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/nn_utils.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(n_epochs, criterion, optimizer, model, trainloader, validloader, device)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mrunning_valid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HprOPCtaPIH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_drop.state_dict(), 'model_drop.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0GuJOH3VGGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model_bn_dropout = AE_3d_bn_dropout().to(device)\n",
        "#criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model_bn_dropout.parameters(), lr=1e-4, weight_decay=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMbOVsP9VxSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "c7bde7a3-234a-45a1-e628-bb88cbe9d057"
      },
      "source": [
        "model_bn_dropout, train_losses, valid_losses = fit(5, criterion, optimizer, model_bn_dropout, trainloader, validloader, device)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1, Training loss: 0.1095821287293194, Validation loss: 0.11421487774930093\n",
            "Validation loss decreased (inf --> 0.11421487774930093).  Saving model ...\n",
            "Epoch: 2, Training loss: 0.10913719898318999, Validation loss: 0.11400134608285924\n",
            "Validation loss decreased (0.11421487774930093 --> 0.11400134608285924).  Saving model ...\n",
            "Epoch: 3, Training loss: 0.1078958154651195, Validation loss: 0.11416777284513281\n",
            "Epoch: 4, Training loss: 0.10929384766094297, Validation loss: 0.1145859849159723\n",
            "Epoch: 5, Training loss: 0.10886714970836929, Validation loss: 0.11493220241224603\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cy3lnmG1ajB5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The model was trained for 40 epochs total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EBtXnqvjPNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model_bn_dropout.state_dict(), 'model_bn_dropout.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGbhcJqDjo8F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}